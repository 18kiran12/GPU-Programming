{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>CUDA PROGRAMMING</center></h2>\n",
    "First component of a typical CUDA program is the kernel program which is marked with a global keyword.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kernel function to add the elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is executed by an array of CUDA threads called thread blocks and each thread has an id with which it uses memory adresses and makes informed decisions. These 1000's of threads can be executed in GPU and CUDA organizes these threads into Grids heirarchy of thread blocks.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/cuda_indexing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Grid is a set of thread blocks that can be processed on the device in parallel. A block is a set of concurrent threads that can cooperate among themselves and access a shared memory space private to the block.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/Block-thread.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>How CUDA GPU processes a 512x512 image </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want one thread to process one pixel (i,j)<br>\n",
    "1. We can use blocks of 64 threads each. A block is executed by a single multiprocessing unit. Then we need 512*512/64 = 4096 blocks (so to have 512x512 threads = 4096*64).<br>\n",
    "2. It's common to organize (to make indexing the image easier) the threads in 2D blocks having blockDim = 8 x 8 (the 64 threads per block)\n",
    "3. Set grid dimension as 2D gridDim = 64 x 64 blocks (the 4096 blocks needed)\n",
    "4. Then the kernel is launched as myKernel <<<numBlocks,threadsPerBlock>>>\n",
    "5. Finally: there will be something like \"a queue of 4096 blocks\", where a block is waiting to be assigned one of the multiprocessors of the GPU to get its 64 threads executed\n",
    "\n",
    "<h8>Source : https://stackoverflow.com/questions/2392250/understanding-cuda-grid-dimensions-block-dimensions-and-threads-organization-s</h8>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>A simple Cpp program in C++ to add arrays</h4>\n",
    "Source : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <math.h>\n",
    "#include <ctime>\n",
    "using namespace std;\n",
    "\n",
    "//function to add two arrays\n",
    "void add(int N, float *x, float *y)\n",
    "{\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    y[i] = x[i] + y[i];\n",
    "  }\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  clock_t begin_time = clock(); //set begin time\n",
    "\n",
    "  int N = 1<<20; // 1 Million elements\n",
    "\n",
    "  float *x = new float[N]; //pointer to the big array\n",
    "  float *y = new float[N];\n",
    "  /*A pointer is a variable whose value is the address of another variable*/\n",
    "\n",
    "  //initialize these arrays with values\n",
    "  for(int i = 0; i < N; i++)\n",
    "  {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  //add the two variables together\n",
    "  add(N, x, y);\n",
    "\n",
    "  //Free memory\n",
    "  delete [] x;\n",
    "  delete [] y;\n",
    "  clock_t end_time = clock();\n",
    "  float diff ((float)end_time - (float)begin_time);\n",
    "  float seconds = diff/CLOCKS_PER_SEC;\n",
    "  cout << \"time taken\" <<endl;\n",
    "  cout << end_time;\n",
    "  cout << seconds << endl;\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>A simple CUDA program in C++ to add arrays</h4>\n",
    "Source : https://github.com/llSourcell/An_Introduction_to_GPU_Programming/blob/master/add.cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <math.h>\n",
    "// Kernel function to add the elements of two arrays\n",
    "__global__\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  int index = threadIdx.x;\n",
    "  int stride = blockDim.x;\n",
    "  for (int i = index; i < n; i += stride)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20;\n",
    "  float *x, *y;\n",
    "\n",
    "  // Allocate Unified Memory â€“ accessible from CPU or GPU\n",
    "  cudaMallocManaged(&x, N*sizeof(float));\n",
    "  cudaMallocManaged(&y, N*sizeof(float));\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 1M elements on the GPU\n",
    "  add<<<1, 256>>>(N, x, y);\n",
    "\n",
    "  // Wait for GPU to finish before accessing on host\n",
    "  cudaDeviceSynchronize();\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  cudaFree(x);\n",
    "  cudaFree(y);\n",
    "  \n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
